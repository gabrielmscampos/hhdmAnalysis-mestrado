{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a131de-cde0-4ebc-a503-97c76ce87521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 19:58:48.612238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-16 19:58:52.480845: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-16 19:58:52.489548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-16 19:58:53.156582: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-16 19:58:53.156882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA GeForce GTX 1660 computeCapability: 7.5\n",
      "coreClock: 1.8GHz coreCount: 22 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.86GiB/s\n",
      "2023-02-16 19:58:53.157019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-16 19:58:53.203779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-02-16 19:58:53.204078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-16 19:58:53.224244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-16 19:58:53.226509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-16 19:58:53.272615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-16 19:58:53.279063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-02-16 19:58:53.280301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-16 19:58:53.280623: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-16 19:58:53.280832: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-16 19:58:53.281092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import anatools.data as data\n",
    "import tensorflow as tf\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from hhdm_analysis.xgb.controllers import XGBLearner, XGBModel\n",
    "\n",
    "# Disable GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933516cd-e817-4980-bb32-c02c4960ce72",
   "metadata": {},
   "source": [
    "# Setup config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad288b9-b7f7-4c4d-9468-e96796fdb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = '18'\n",
    "year_style = 2018\n",
    "dataset_year = \"2018\"\n",
    "basedir = \"/home/gamoreir/SanDisk/physics/hhdmAnalysis_deepJet_Regions/datasets\"\n",
    "\n",
    "# Data folder\n",
    "dataset_name = basedir.split('/')[-2]\n",
    "data_path = f\"./data/{dataset_name}/{dataset_year}\"\n",
    "Path(data_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Setup models folders\n",
    "models_path = f\"./models/{dataset_name}/{dataset_year}\"\n",
    "Path(models_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fa024-1c8c-4459-ba59-fb214e27e04c",
   "metadata": {},
   "source": [
    "# Read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cda459-65fe-4604-be8c-3e7b3daf7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "ST = metadata.get(\"datasets\").get(\"ST\")\n",
    "TT = metadata.get(\"datasets\").get(\"TT\")\n",
    "ZZ = metadata.get(\"datasets\").get(\"ZZ\")\n",
    "WZ = metadata.get(\"datasets\").get(\"WZ\")\n",
    "DY = metadata.get(\"datasets\").get(\"DY\")\n",
    "RESIDUAL = metadata.get(\"datasets\").get(\"RESIDUAL\")\n",
    "DATA = metadata.get(\"datasets\").get(\"DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8d603-8d39-4214-91d3-bdf1dbe58563",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2607f4d-60f1-44d8-9775-bf17fb1f1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:06<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal_1000_100 (184662, 13)\n",
      "Signal_1000_200 (155516, 13)\n",
      "Signal_1000_300 (163180, 13)\n",
      "Signal_1000_400 (174503, 13)\n",
      "Signal_1000_600 (47113, 13)\n",
      "Signal_1000_800 (148510, 13)\n",
      "Signal_400_100 (112655, 13)\n",
      "Signal_400_200 (35615, 13)\n",
      "Signal_500_100 (130495, 13)\n",
      "Signal_500_200 (140136, 13)\n",
      "Signal_500_300 (118287, 13)\n",
      "Signal_600_100 (134052, 13)\n",
      "Signal_600_200 (156038, 13)\n",
      "Signal_600_300 (145565, 13)\n",
      "Signal_600_400 (128733, 13)\n",
      "Signal_800_100 (156662, 13)\n",
      "Signal_800_200 (148385, 13)\n",
      "Signal_800_300 (160871, 13)\n",
      "Signal_800_400 (169710, 13)\n",
      "Signal_800_600 (138418, 13)\n",
      "ST (94330, 13)\n",
      "TT (2647163, 13)\n",
      "ZZ (1924672, 13)\n",
      "WZ (24816, 13)\n",
      "DYJetsToLL (5897214, 13)\n",
      "Residual (537577, 13)\n"
     ]
    }
   ],
   "source": [
    "variables = [\"RegionID\", \"evtWeight\", \"MLP_score_torch\", \"LeadingLep_pt\", \"LepLep_pt\", \"LepLep_deltaR\", \"LepLep_deltaM\", \"MET_pt\", \"MET_LepLep_Mt\", \"MET_LepLep_deltaPhi\", \"TrailingLep_pt\", \"MT2LL\", \"Nbjets\"]\n",
    "ds = data.read_files(basedir, period, mode=\"normal\", features=variables)\n",
    "\n",
    "data.join_datasets(ds, \"ST\", ST.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"TT\", TT.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"ZZ\", ZZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"WZ\", WZ.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"DYJetsToLL\", DY.get(period), mode=\"normal\")\n",
    "data.join_datasets(ds, \"Residual\", RESIDUAL.get(period), mode=\"normal\")\n",
    "\n",
    "# Datasets to be used\n",
    "used_datasets = [\n",
    "    *[dt for dt in ds.keys() if dt.startswith(\"Signal_\")],\n",
    "    \"ST\",\n",
    "    \"TT\",\n",
    "    \"ZZ\",\n",
    "    \"WZ\",\n",
    "    \"DYJetsToLL\",\n",
    "    \"Residual\"\n",
    "]\n",
    "\n",
    "for dt_name in used_datasets:\n",
    "    print(dt_name, ds[dt_name].shape)\n",
    "\n",
    "# Delete every other dataset\n",
    "datasets_to_delete = [dt_name for dt_name in ds.keys() if dt_name not in used_datasets]\n",
    "for dt_name in datasets_to_delete:\n",
    "    del ds[dt_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed65a04-0204-480a-b8e7-a104e9976e97",
   "metadata": {},
   "source": [
    "# Models metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b475a9f8-f079-450b-90e3-cdc8247574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"multi_signal\"\n",
    "features = [\n",
    "    \"LeadingLep_pt\",\n",
    "    \"LepLep_deltaM\",\n",
    "    \"LepLep_deltaR\",\n",
    "    \"LepLep_pt\",\n",
    "    \"MET_LepLep_Mt\",\n",
    "    \"MET_LepLep_deltaPhi\",\n",
    "    \"MET_pt\",\n",
    "    \"MT2LL\",\n",
    "    \"Nbjets\",\n",
    "    \"TrailingLep_pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676f3e4-fb4c-43ce-af32-dbbedfbe4723",
   "metadata": {},
   "source": [
    "# Predict using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb55b752-3d9c-43d4-b78c-395b368af69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:21<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "xgb_model = XGBModel(model_fpath=f\"{models_path}/XGB_{base_model_name}-clf.model\")\n",
    "\n",
    "# Predict each dataset\n",
    "for dataset_name, dataset in tqdm(ds.items()):\n",
    "    X_features = dataset[features]\n",
    "    Y_pred = xgb_model.predict(X_features, features)\n",
    "    dataset[\"XGB_score\"] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5902e39-4d47-4277-a07e-5eb0aaffa952",
   "metadata": {},
   "source": [
    "# Pedrict using MLP Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083a4736-ce08-4c35-8b2c-b3f611bea625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 19:59:22.071587: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-16 19:59:22.071867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-16 19:59:22.071890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "  0%|          | 0/26 [00:00<?, ?it/s]2023-02-16 20:00:04.487995: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-02-16 20:00:04.490778: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599995000 Hz\n",
      "100%|██████████| 26/26 [1:07:35<00:00, 155.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "mlp_model = load_model(f\"{models_path}/MLP_{base_model_name}-checkpoint.h5\")\n",
    "\n",
    "# Load zscore stats\n",
    "zscore = json.load(open(f\"{data_path}/MLP_{base_model_name}-weighted_stats.json\", \"r\"))\n",
    "\n",
    "# Predict each dataset\n",
    "for dataset_name, dataset in tqdm(ds.items()):\n",
    "    X_features = dataset[features].copy()\n",
    "    \n",
    "    # Since the model was trained under processed data, we need to preprocess it to predict\n",
    "    for feature in features:\n",
    "        X_features.loc[:, feature] = (X_features[feature] - zscore[feature][\"mean\"]) / zscore[feature][\"std\"]\n",
    "\n",
    "    Y_pred = mlp_model.predict(X_features, batch_size=256)\n",
    "    dataset[\"MLP_score_keras\"] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d511b-3efa-4e88-bece-3594818a11cf",
   "metadata": {},
   "source": [
    "# Save predict datasets\n",
    "\n",
    "Prediction plots will be made in another jupyter notebook for the sake of flexibility since Keras prediction is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd47d39-875d-4da4-b62b-88a7b3b29d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}/{base_model_name}-predicted-data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ccc2c-f3a2-4265-a85e-8cb07a4a86ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
